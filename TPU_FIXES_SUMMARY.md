# Kaggle TPU v5e-8 ä¿®å¤æ€»ç»“

## âœ… å·²ä¿®å¤çš„é”™è¯¯

### 1. **DeprecationWarning: Use torch_xla.device instead**
```python
# âŒ æ—§ä»£ç 
device = xm.xla_device()

# âœ… æ–°ä»£ç 
import torch_xla
device = torch_xla.device()
```

### 2. **AttributeError: module 'torch_xla.core.xla_model' has no attribute 'get_world_size'**
```python
# âŒ æ—§ä»£ç 
gpus = xm.get_world_size()
is_main_process = xm.is_master_ordinal()

# âœ… æ–°ä»£ç 
gpus = 8  # Kaggle TPU v5e-8 å›ºå®šå€¼
is_main_process = True  # å•èŠ‚ç‚¹ç¯å¢ƒ
```

### 3. **Accelerator API ä¸å…¼å®¹**
ä¿®æ”¹äº†ä»¥ä¸‹æ–¹æ³•æ¥é€‚é… TPUï¼š

```python
# Backward pass
# âŒ accelerator.backward(loss)
# âœ… loss.backward() + xm.mark_step()

# æ¢¯åº¦è£å‰ª
# âŒ accelerator.clip_grad_norm_()
# âœ… torch.nn.utils.clip_grad_norm_()

# Gather æ“ä½œï¼ˆTPU å•èŠ‚ç‚¹ä¸éœ€è¦ï¼‰
# âŒ accelerator.gather(tensor)
# âœ… if not HAS_TPU: accelerator.gather(tensor)

# æ‰“å°è¾“å‡º
# âŒ accelerator.print()
# âœ… if HAS_TPU: print() else: accelerator.print()
```

## ğŸ“‹ ä»£ç æ”¹åŠ¨æ¸…å•

### main.py ä¸­çš„æ”¹åŠ¨

| è¡Œå· | æ”¹åŠ¨å†…å®¹ |
|------|---------|
| 30-42 | æ·»åŠ  torch-xla æ£€æµ‹å’Œæ¡ä»¶å¯¼å…¥ |
| 100-141 | é‡å†™ main() å‡½æ•°çš„è®¾å¤‡åˆå§‹åŒ– |
| 296-324 | ä¿®å¤è®­ç»ƒå¾ªç¯ä¸­çš„ backward/gather è°ƒç”¨ |
| 338-343 | æ·»åŠ æ¡ä»¶ gather() é€»è¾‘ |
| 379-391 | æ·»åŠ æ¡ä»¶ gather() å’Œ print() é€»è¾‘ |
| 409-434 | é‡å†™ test() å‡½æ•°çš„è®¾å¤‡åˆå§‹åŒ– |
| 481-488 | ä¿®å¤ DataLoader prepare å’Œ print è°ƒç”¨ |
| 506-569 | ä¿®å¤æµ‹è¯•å¾ªç¯ä¸­çš„ gather å’Œ print è°ƒç”¨ |

## ğŸš€ ç°åœ¨å¯ä»¥è¿è¡Œ

### ç›´æ¥è¿è¡Œï¼ˆæ¨èï¼‰
```bash
python main.py --mode train --data-path /kaggle/input/simdata-cdeit --global-batch-size 64
```

### å®Œæ•´ç¤ºä¾‹
```bash
python main.py \
  --mode train \
  --data-path /kaggle/input/simdata-cdeit \
  --global-batch-size 64 \
  --epochs 100 \
  --global-seed 0 \
  --log-every 50 \
  --ckpt-every 500
```

## âœ… éªŒè¯ä¿®å¤

è¿è¡Œä»¥ä¸‹å‘½ä»¤æ£€æŸ¥æ˜¯å¦æ­£ç¡®ï¼š

```bash
# æ£€æŸ¥ TPU æ£€æµ‹
python -c "
import torch_xla
try:
    device = torch_xla.device()
    print('âœ… TPU å¯ç”¨:', device)
except:
    print('âš ï¸ TPU ä¸å¯ç”¨ï¼Œä½¿ç”¨ CPU')
"

# æ£€æŸ¥ä»£ç è¯­æ³•
python -m py_compile main.py && echo "âœ… è¯­æ³•æ­£ç¡®"

# è¿è¡Œå¿«é€Ÿæµ‹è¯•ï¼ˆåªè®­ç»ƒ 1 ä¸ª epochï¼‰
python main.py --mode train --epochs 1 --log-every 5
```

## ğŸ“Š é¢„æœŸè¡Œä¸º

### TPU æ¨¡å¼ï¼ˆKaggle TPU v5e-8ï¼‰
- âœ… è‡ªåŠ¨æ£€æµ‹ TPU
- âœ… ä½¿ç”¨ BF16 ç²¾åº¦ï¼ˆå¿« 2-3 å€ï¼‰
- âœ… å•èŠ‚ç‚¹è¿è¡Œï¼Œæ— åˆ†å¸ƒå¼å¼€é”€
- âš¡ è®­ç»ƒé€Ÿåº¦: æ¯ epoch çº¦ 2-3 åˆ†é’Ÿï¼ˆ1000 å¼ å›¾ç‰‡ï¼‰

### GPU æ¨¡å¼ï¼ˆæœ¬åœ° NVIDIA GPUï¼‰
- âœ… è‡ªåŠ¨æ£€æµ‹ GPU
- âœ… ä½¿ç”¨ FP16 ç²¾åº¦
- âœ… é€šè¿‡ Accelerate å¤„ç†åˆ†å¸ƒå¼
- âš¡ è®­ç»ƒé€Ÿåº¦: å–å†³äº GPU å‹å·

## ğŸ”§ å…³é”®æ”¹åŠ¨æ€»ç»“

| åŠŸèƒ½ | TPU | GPU |
|------|-----|-----|
| è®¾å¤‡è·å– | `torch_xla.device()` | `accelerator.device` |
| Backward | `loss.backward()` + `xm.mark_step()` | `accelerator.backward()` |
| æ¢¯åº¦è£å‰ª | `torch.nn.utils.clip_grad_norm_()` | `accelerator.clip_grad_norm_()` |
| Gather | è·³è¿‡ï¼ˆå•èŠ‚ç‚¹ï¼‰ | `accelerator.gather()` |
| æ‰“å° | `print()` | `accelerator.print()` |
| ç²¾åº¦ | BF16 | FP16 |

## âš ï¸ å·²çŸ¥é™åˆ¶

1. **å•èŠ‚ç‚¹è¿è¡Œ**: Kaggle TPU v5e-8 åªæ”¯æŒå•èŠ‚ç‚¹ï¼Œå¤šèŠ‚ç‚¹ TPU Pod éœ€è¦é¢å¤–é…ç½®
2. **BF16 ç²¾åº¦**: æŸäº›å¯¹ç²¾åº¦æä¸ºæ•æ„Ÿçš„æ“ä½œå¯èƒ½éœ€è¦æ‰‹åŠ¨è½¬ä¸º FP32
3. **æ•°æ®åŠ è½½**: åœ¨ TPU ä¸Šï¼Œæ•°æ®åŠ è½½é€Ÿåº¦å¯èƒ½å—é™ï¼Œå»ºè®®ä½¿ç”¨ prefetch

## ä¸‹ä¸€æ­¥

1. âœ… ä»£ç å·²ä¿®å¤ï¼Œå¯ä»¥ç›´æ¥è¿è¡Œ
2. ğŸ“Š ç›‘æ§è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŸå¤±å˜åŒ–
3. ğŸ’¾ ç»“æœä¿å­˜åœ¨ `./results/deit/checkpoints/`

---

**ä¿®å¤æ—¥æœŸ**: 2025-01-03
**ç¯å¢ƒ**: Kaggle TPU v5e-8 with torch-xla
