\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{borsic2009vivo}
\citation{karhunen2010electrical}
\citation{somersalo1992existence}
\@writefile{toc}{\contentsline {section}{\tocsection {}{1}{Introduction}}{1}{section.1}\protected@file@percent }
\newlabel{eq:maxwelleqn}{{1}{1}{Introduction}{equation.1}{}}
\newlabel{eq:maxwell1}{{1a}{1}{Introduction}{equation.1a}{}}
\citation{rasanen2023kuopio}
\newlabel{eq:CEM}{{1b}{2}{Introduction}{equation.1b}{}}
\newlabel{eq:conservation_of_charge}{{1c}{2}{Introduction}{equation.1c}{}}
\newlabel{eq:nonlinear_ip}{{2}{2}{Introduction}{equation.2}{}}
\newlabel{subsec:ktc_challenge_description}{{1.1}{2}{KTC 2023 Challenge}{subsection.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{1.1}{KTC 2023 Challenge}}{2}{subsection.1.1}\protected@file@percent }
\newlabel{sec:contribution}{{1.2}{2}{Our Contribution}{subsection.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{1.2}{Our Contribution}}{2}{subsection.1.2}\protected@file@percent }
\citation{arridge2019solving}
\citation{chen2020deep}
\citation{martin2017post}
\citation{wang2024comparative}
\citation{chung2022come}
\citation{cheney1990noser}
\citation{dobson1994image}
\citation{kaipio2000statistical}
\newlabel{fig:eit_illustration}{{1.1}{3}{KTC 2023 Challenge}{subsection.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces An illustration of the EIT measurement tank ($\Omega $), the electrodes $e_l$, with a sample of the injection patterns. In black we show the \emph  {adjacent} injections; in green \emph  {all against} $e_1$; in pink \emph  {all against} $e_9$; in magenta \emph  {all against} $e_{17}$; in orange \emph  {all against} $e_{25}$. Dashed injection are removed in the $2^{\text  {nd}}$ challenge level; dotted ones in the $4^{\text  {th}}$; dash dotted in the $6^{\text  {th}}$.}}{3}{figure.1}\protected@file@percent }
\newlabel{sec:relatedwork}{{1.3}{3}{Related Work}{subsection.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{1.3}{Related Work}}{3}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\tocsection {}{2}{Linearised Reconstruction}}{3}{section.2}\protected@file@percent }
\citation{hyvonen2004complete}
\citation{kaipio2000statistical}
\newlabel{eq:linearised_ip}{{4}{4}{Linearised Reconstruction}{equation.4}{}}
\newlabel{eq:var_probl}{{5}{4}{Linearised Reconstruction}{equation.5}{}}
\newlabel{eq:lin_rec_one_step}{{6}{4}{Linearised Reconstruction}{equation.6}{}}
\newlabel{sec:forward_operator}{{2.1}{4}{Forward Operator}{subsection.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{2.1}{Forward Operator}}{4}{subsection.2.1}\protected@file@percent }
\newlabel{eq:CEM_weak_formulation}{{7}{4}{Forward Operator}{equation.7}{}}
\newlabel{eq:linear_system_cem}{{8}{4}{Forward Operator}{equation.8}{}}
\citation{BarattaEtal2023}
\citation{dobson1994image}
\citation{kaipio2000statistical}
\citation{GEHRE20122126}
\newlabel{sec:jacobian}{{2.2}{5}{Jacobian}{subsection.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{2.2}{Jacobian}}{5}{subsection.2.2}\protected@file@percent }
\newlabel{eq:construct_jacobian}{{9}{5}{Jacobian}{equation.9}{}}
\newlabel{eq:jacobi_problem}{{10}{5}{Jacobian}{equation.10}{}}
\newlabel{eq:linear_system_jacobian}{{11}{5}{Jacobian}{equation.11}{}}
\citation{borsic2009vivo}
\citation{rasanen2023kuopio}
\citation{fletcher1971modified}
\citation{cheney1990noser}
\newlabel{eq:fast_jacobian}{{14}{6}{Jacobian}{equation.14}{}}
\newlabel{sec:initial_reconstruction}{{2.3}{6}{Regularisation}{subsection.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{2.3}{Regularisation}}{6}{subsection.2.3}\protected@file@percent }
\newlabel{eq:initial_reco}{{16}{6}{Regularisation}{equation.16}{}}
\citation{ronneberger2015u}
\citation{dhariwal2021diffusion}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Example initial reconstructions on challenge levels 1 and 6. Level 6 was chosen as it best highlights differences in linearised reconstructions. We evaluate an independent FSM prior, independent SM prior, joint SM+LM prior and two joint priors FSM+SM+LM with different regularisation strengths. The chosen image is a sample of the validation data.}}{7}{figure.2}\protected@file@percent }
\newlabel{fig:initial_reco}{{2}{7}{Example initial reconstructions on challenge levels 1 and 6. Level 6 was chosen as it best highlights differences in linearised reconstructions. We evaluate an independent FSM prior, independent SM prior, joint SM+LM prior and two joint priors FSM+SM+LM with different regularisation strengths. The chosen image is a sample of the validation data}{figure.2}{}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{3}{Deep Learning Approaches}}{7}{section.3}\protected@file@percent }
\citation{ongie2020deep}
\citation{arndt2023model}
\citation{ongie2020deep}
\citation{schwab2019deep}
\citation{chen2020deep}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{3.1}{Learned Reconstructors}}{8}{subsection.3.1}\protected@file@percent }
\newlabel{sec:FCUNet}{{3.1.1}{8}{\FullyC }{subsubsection.3.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\tocsubsubsection {}{3.1.1}{\textsf  {FC U-Net}}}{8}{subsubsection.3.1.1}\protected@file@percent }
\citation{dhariwal2021diffusion}
\citation{arridge2019solving}
\citation{ongie2020deep}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textsf  {FC U-Net}\nonbreakingspace  network. We first use a linear layer to map the measurements to a $64 \times 64$ pixel grid, this is then bilinearly interpolated to the $256 \times 256$ grid. The network is trained to output class probabilities using categorical cross-entropy loss. The class probabilities are converted to segmentation maps by assigning the class with highest probability.}}{9}{figure.3}\protected@file@percent }
\newlabel{fig:fcUNet}{{3}{9}{\FullyC ~ network. We first use a linear layer to map the measurements to a $64 \times 64$ pixel grid, this is then bilinearly interpolated to the $256 \times 256$ grid. The network is trained to output class probabilities using categorical cross-entropy loss. The class probabilities are converted to segmentation maps by assigning the class with highest probability}{figure.3}{}}
\newlabel{eq:cce}{{24}{9}{\FullyC }{equation.24}{}}
\newlabel{sec:post_unet}{{3.1.2}{9}{\PostP }{subsubsection.3.1.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\tocsubsubsection {}{3.1.2}{\textsf  {Post-Processing}}}{9}{subsubsection.3.1.2}\protected@file@percent }
\citation{stuart2010inverse}
\citation{ho2020denoising}
\citation{sohl2015deep}
\citation{dhariwal2021diffusion}
\citation{saharia2022image}
\citation{tashiro2021csdi}
\citation{batzolis2021conditional}
\citation{batzolis2021conditional}
\citation{ho2020denoising}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textsf  {Post-Processing}\nonbreakingspace  network. The five linearised reconstructions are interpolated to the pixel grid as described in Section\nonbreakingspace \ref {sec:initial_reconstruction}. The network is trained to output class probabilities using categorical cross-entropy loss. The class probabilities are converted to segmentation maps by assigning the class with highest probability.}}{10}{figure.4}\protected@file@percent }
\newlabel{fig:postprocessingUNet}{{4}{10}{\PostP ~ network. The five linearised reconstructions are interpolated to the pixel grid as described in Section~\ref {sec:initial_reconstruction}. The network is trained to output class probabilities using categorical cross-entropy loss. The class probabilities are converted to segmentation maps by assigning the class with highest probability}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{3.2}{Conditional Density Estimation}}{10}{subsection.3.2}\protected@file@percent }
\newlabel{sec:cond_score}{{3.2.1}{10}{Conditional diffusion models}{subsubsection.3.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\tocsubsubsection {}{3.2.1}{Conditional diffusion models}}{10}{subsubsection.3.2.1}\protected@file@percent }
\citation{ho2020denoising}
\citation{ho2020denoising}
\citation{song2020denoising}
\citation{efron2011tweedie}
\citation{song2020denoising}
\newlabel{eq:forward_onestep}{{28}{11}{Conditional diffusion models}{equation.28}{}}
\newlabel{eq:ddim_sampling}{{30}{11}{Conditional diffusion models}{equation.30}{}}
\citation{vilhunen2002simultaneous}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \textsf  {Conditional-Diffusion}\nonbreakingspace  network. The five linearised reconstructions are interpolated to the pixel grid as described in Section\nonbreakingspace \ref {sec:initial_reconstruction}. The noisy image and linearised reconstructions are input into the network. Using the $\bm  {\epsilon }$-matching loss function, the network is trained to estimate the noise. Through sampling the network a segmentation map is obtained. Multiple samples are drawn through pixel-wise majority voting the final segmentation map is obtained.}}{12}{figure.5}\protected@file@percent }
\newlabel{fig:conddiffUNet}{{5}{12}{\CondD ~ network. The five linearised reconstructions are interpolated to the pixel grid as described in Section~\ref {sec:initial_reconstruction}. The noisy image and linearised reconstructions are input into the network. Using the $\bepsilon $-matching loss function, the network is trained to estimate the noise. Through sampling the network a segmentation map is obtained. Multiple samples are drawn through pixel-wise majority voting the final segmentation map is obtained}{figure.5}{}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{4}{Practical consideration}}{12}{section.4}\protected@file@percent }
\newlabel{sec:dataset}{{4.1}{12}{Dataset}{subsection.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.1}{Dataset}}{12}{subsection.4.1}\protected@file@percent }
\citation{GEHRE20122126}
\citation{borsic2009vivo}
\citation{gmsh2009}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Top: Handdrawn training phantoms. Bottom: Randomly generated training phantoms. For the visualisation, we only show the circular water tank. However, note that all models are trained using the square $256\times 256$ pixel images.}}{13}{figure.6}\protected@file@percent }
\newlabel{fig:training_data}{{6}{13}{Top: Handdrawn training phantoms. Bottom: Randomly generated training phantoms. For the visualisation, we only show the circular water tank. However, note that all models are trained using the square $256\times 256$ pixel images}{figure.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Number of training samples used per level.}}{13}{table.1}\protected@file@percent }
\newlabel{tab:num_training}{{1}{13}{Number of training samples used per level}{table.1}{}}
\newlabel{sec:practical_initReco}{{4.2}{13}{Initial Reconstruction}{subsection.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.2}{Initial Reconstruction}}{13}{subsection.4.2}\protected@file@percent }
\citation{dhariwal2021diffusion}
\citation{ronneberger2015u}
\citation{dhariwal2021diffusion}
\citation{wu2018group}
\citation{wang2004image}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Left: The mesh provided by the organizers. Right: Our custom mesh for the forward operator.}}{14}{figure.7}\protected@file@percent }
\newlabel{fig:mesh}{{7}{14}{Left: The mesh provided by the organizers. Right: Our custom mesh for the forward operator}{figure.7}{}}
\@writefile{toc}{\contentsline {subsection}{\tocsubsection {}{4.3}{Neural Network Architecture}}{14}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\tocsection {}{5}{Results and Discussion}}{14}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\tocsection {}{6}{Conclusion}}{15}{section.6}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Quantitative comparison of our three submissions via structural similarity index measure (SSIM). These are official challenge results, rounded to the nearest hundredth. The second place was achieved by Team ABC from the Federal University of ABC, Brasil. The third place was achieved by Team DTU from Technical University of Denmark. SSIM is averaged for a given sample between conductive and resistive inclusions. At each level the SSIM is summed across the three samples, and the overall sum for a method is summed across all samples and levels.}}{16}{table.2}\protected@file@percent }
\newlabel{tab:full_results}{{2}{16}{Quantitative comparison of our three submissions via structural similarity index measure (SSIM). These are official challenge results, rounded to the nearest hundredth. The second place was achieved by Team ABC from the Federal University of ABC, Brasil. The third place was achieved by Team DTU from Technical University of Denmark. SSIM is averaged for a given sample between conductive and resistive inclusions. At each level the SSIM is summed across the three samples, and the overall sum for a method is summed across all samples and levels}{table.2}{}}
\@writefile{toc}{\contentsline {section}{\tocsection {}{}{Acknowledgments}}{16}{section*.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Segmentation of the three methods for sample $A$ of level $1$ to $7$.}}{17}{figure.8}\protected@file@percent }
\newlabel{fig:reco_sample_A}{{8}{17}{Segmentation of the three methods for sample $A$ of level $1$ to $7$}{figure.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Segmentation of the three methods for sample $B$ of level $1$ to $7$.}}{18}{figure.9}\protected@file@percent }
\newlabel{fig:reco_sample_B}{{9}{18}{Segmentation of the three methods for sample $B$ of level $1$ to $7$}{figure.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Segmentation of the three methods for sample $C$ of level $1$ to $7$.}}{19}{figure.10}\protected@file@percent }
\newlabel{fig:reco_sample_C}{{10}{19}{Segmentation of the three methods for sample $C$ of level $1$ to $7$}{figure.10}{}}
\bibcite{arndt2023model}{1}
\bibcite{arridge2019solving}{2}
\bibcite{BarattaEtal2023}{3}
\bibcite{batzolis2021conditional}{4}
\bibcite{borsic2009vivo}{5}
\bibcite{chen2020deep}{6}
\bibcite{cheney1990noser}{7}
\bibcite{chung2022come}{8}
\bibcite{dhariwal2021diffusion}{9}
\bibcite{dobson1994image}{10}
\bibcite{efron2011tweedie}{11}
\bibcite{fletcher1971modified}{12}
\bibcite{GEHRE20122126}{13}
\bibcite{gmsh2009}{14}
\bibcite{ho2020denoising}{15}
\bibcite{hyvonen2004complete}{16}
\bibcite{kaipio2000statistical}{17}
\bibcite{karhunen2010electrical}{18}
\bibcite{martin2017post}{19}
\bibcite{ongie2020deep}{20}
\bibcite{rasanen2023kuopio}{21}
\bibcite{ronneberger2015u}{22}
\bibcite{saharia2022image}{23}
\bibcite{schwab2019deep}{24}
\@writefile{toc}{\contentsline {section}{\tocsection {}{}{REFERENCES}}{20}{section*.2}\protected@file@percent }
\bibcite{sohl2015deep}{25}
\bibcite{somersalo1992existence}{26}
\bibcite{song2020denoising}{27}
\bibcite{stuart2010inverse}{28}
\bibcite{tashiro2021csdi}{29}
\bibcite{vilhunen2002simultaneous}{30}
\bibcite{wang2024comparative}{31}
\bibcite{wang2004image}{32}
\bibcite{wu2018group}{33}
\newlabel{tocindent-1}{0pt}
\newlabel{tocindent0}{14.69437pt}
\newlabel{tocindent1}{20.44434pt}
\newlabel{tocindent2}{29.38873pt}
\newlabel{tocindent3}{0pt}
\gdef \@abspage@last{21}
