"""
论文中的CNN-EIM网络架构分析
根据论文 "Image reconstruction for electrical impedance tomography
based on spatial invariant feature maps and convolutional neural network"
"""

# 论文中的网络架构（从PDF第2页图4提取）：

# 输入: 1×16×16 EIM
# 输出: 1×64×64 重建图像

# 详细架构：
# Conv(1,64) -> BN -> PReLU -> MaxPool
# Conv(64,128) -> BN -> PReLU -> MaxPool
# Conv(128,256) -> BN -> PReLU -> MaxPool
# Conv(256,256) -> BN -> PReLU -> MaxPool
# Conv(256,256) -> BN -> PReLU -> MaxPool

# 然后是反卷积层：
# DeConv(256,128) -> BN -> LeakyReLU
# DeConv(128,64) -> BN -> LeakyReLU
# DeConv(64,32) -> BN -> LeakyReLU
# DeConv(32,1) -> Tanh

# 关键特点：
# 1. 编码器-解码器结构（类似U-Net但不完全相同）
# 2. 没有Skip Connection
# 3. 使用MaxPool下采样，DeConv上采样
# 4. 最后层使用Tanh激活
# 5. 卷积核大小: 3×3, padding=1, stride=1
# 6. 反卷积核大小: 2×2, padding=0, stride=2
# 7. MaxPool核大小: 2×2, stride=2

print("""
论文中的CNN-EIM网络架构特点：

1. 网络结构：
   - 编码器：5个卷积层（逐步下采样）
   - 解码器：4个反卷积层（逐步上采样）
   - 无Skip Connection
   - 输入: 1×16×16, 输出: 1×64×64

2. 激活函数：
   - 编码部分: PReLU
   - 解码部分: LeakyReLU
   - 输出层: Tanh（用于归一化到[-1,1]范围）

3. 批量归一化：
   - 每个卷积层后都有BN

4. 参数设置：
   - Conv: kernel=3×3, padding=1, stride=1
   - DeConv: kernel=2×2, padding=0, stride=2
   - MaxPool: kernel=2×2, stride=2

5. 关键优势：
   - 针对16×16 EIM输入专门设计
   - 输出64×64（比128×128更合理）
   - 参数相对较少
   - 适合EIM的结构化特性
""")
